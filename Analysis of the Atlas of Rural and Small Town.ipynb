{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do wildfires burn up jobs in rural California? \n",
    "# Investigating the impact of wildifre size on rural economies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### Motivation\n",
    "Global climate change is driving increases in wildfire occurence and intensity, while increasing anthropogenic land use brings humans in more contact with wilderness areas with greater fire risks. Major Californian wildfires have garnered global news attention and caused great financial dammage and human suffering. Understanding the effects of wildfire on humans and economies on local/regional scales will aid in better planning for a future where risk of wildfire is higher. Here, I invesitgate the relationship between wildfire area and socioeconomic in rural counties in California.\n",
    "\n",
    "### Hypotheses (Incomplete)\n",
    "Wildfires are devastating natural disasters that not only dirupt the lives and economies of the communities where they occur, but may also have significant post-fire effects that prevent a return to normalacy (which itself has cascading effects). Rural californian counties that experience higher wildfire occurrence may experience decreases in population and  employment rates following the event. I test the following hypotheses:\n",
    "1) \n",
    "2) \n",
    "3)\n",
    "\n",
    "### Data Sources\n",
    "Socioeconomic data at the county level is available from the [Atlas of Rural and Small Town America](https://catalog.data.gov/dataset/atlas-of-rural-and-small-town-america) (Economic Research Service, United States Department of Agriculture, 2021). Wildfire data was drawn from the Kaggle dataset [California WildFires (2013-2020)](https://www.kaggle.com/ananthu017/california-wildfire-incidents-20132020?select=California_Fire_Incidents.csv) (Kaggle User Ares, 2020).\n",
    "\n",
    "### Methods (Incomplete)\n",
    "First, I prepared the socioeconomic statistics and population estimate tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "I begin by improtign the Python libraries I will use in this analysis, along with the datasets I will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and format Rural Atlas of America data\n",
    "\n",
    "First, I import all three datasets I will be using (see Overview: Data Sources for more information) and clean the Rural Atlas of America datasets to include only Californian data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Rural Atlas population estimates\n",
    "people = pd.read_csv('people.csv')  \n",
    "\n",
    "# Import Rural Atlas employment metrics.\n",
    "jobs = pd.read_csv('jobs.csv') \n",
    "\n",
    "# Import California Wildfire dataset.\n",
    "fires = pd.read_csv('California_Fire_Incidents.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that five variables in the jobs.csv dataset are inconsitently named and have an extra letter capitalized (e.g. NumCivLaborforce2011 vs NumCivLaborForce2011). The affected variables are: 'NumCivLaborforce2011', 'NumCivLaborforce2009', 'NumCivLaborforce2012', 'NumCivLaborforce2008', and 'NumCivLaborforce2010'. These were fixed manually by editing the jobs.csv data table in MS Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only counties in California for the:\n",
    "# jobs dataset,\n",
    "jobs = jobs[jobs['State'] == 'CA'] \n",
    "# and the people dataset.\n",
    "people = people[people['State'] == 'CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By creating a helper function, separateData(), I can retrieve a useful subset of data in each Rural Atlas of America dataset and place it in a new dataframe for further manipulation and analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateData(df, lst, y1, y2):\n",
    "    \"\"\"Select data from main table using a list of row names and transpose.\n",
    "\n",
    "    df == parent dataframe (array)\n",
    "    lst == a list of column names to select from the df (list)\n",
    "    y1 == the first year of data available\n",
    "    y2 == the last year of data available\n",
    "    \"\"\"\n",
    "    \n",
    "    dfname = df[lst]\n",
    "    # Remove State column.\n",
    "    dfname = dfname.drop('State', 1) \n",
    "    # Make County column new index.\n",
    "    dfname = dfname.set_index('County')\n",
    "    # Transpose so columns are names while rows are years. \n",
    "    dfname = dfname.transpose()\n",
    "\n",
    "    # Initialize a list of years for the specified time period.\n",
    "    years = list(range(y1, y2 + 1)) \n",
    "    # Format values as strings.\n",
    "    years = [str(x) for x in years]\n",
    "    # Zip years with the matching column name into a dictionary.\n",
    "    indices = dict(zip(lst[2:], years))\n",
    "\n",
    "    # Rename the index column with the year values in the indices dictionary.\n",
    "    dfname.rename(index=indices, inplace=True)\n",
    "\n",
    "    # Return the dataframe.\n",
    "    return dfname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use another helper function to prepare strings of columns names to be used as input for the lst variable for the separateData() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colNameList(name, y1, y2):\n",
    "    \"\"\"Generate a list of variable names for repeating years.\n",
    "\n",
    "    name == the base variable name.\n",
    "    y1 == the first year of data available.\n",
    "    y2 == the last year of data available.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list with preset first two values.\n",
    "    lst = ['State', 'County']\n",
    "    # Initialize a list of the years this function produces variables for.\n",
    "    years = list(range(y1, y2 + 1))\n",
    "    \n",
    "    # Repeat for each year.\n",
    "    for x in years:\n",
    "        # Combine name and year into one string.\n",
    "        value = str(name) + str(x)\n",
    "        # Append combined name-year string to the list.\n",
    "        lst.append(value)\n",
    "    \n",
    "    # Return the list\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper function colNameList() to initialize lists of names for:\n",
    "# Population estimates,\n",
    "population = colNameList('TotalPopEst', 2010, 2019)\n",
    "# Civilian labor force size,\n",
    "labor = colNameList('NumCivLaborforce', 2007, 2020)\n",
    "# Number of employed people,\n",
    "emp = colNameList('NumEmployed', 2007, 2020)\n",
    "# Unemplyment rates, and\n",
    "unempr = colNameList('UnempRate', 2007, 2020)\n",
    "# Number of unemployed people.\n",
    "unemp = colNameList('NumUnemployed', 2007, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper function separateData() to separate and format tables for:\n",
    "# Population estimates, \n",
    "npop = separateData(people, population, 2010, 2019)\n",
    "# Civilian labor force size,\n",
    "nlabor = separateData(jobs, labor, 2007, 2020)\n",
    "# Number of employed people,\n",
    "nemp = separateData(jobs, emp, 2007, 2020)\n",
    "# Unemplyment rates, and\n",
    "runemp = separateData(jobs, unempr, 2007, 2020)\n",
    "# Number of unemployed people.\n",
    "numemp = separateData(jobs, unemp, 2007, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and prepare wildfire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows for States of Oregon, Nevada, and Mexico\n",
    "fires = fires[fires['Counties'] != 'State of Oregon'] \n",
    "fires = fires[fires['Counties'] != 'State of Nevada']\n",
    "fires = fires[fires['Counties'] != 'Mexico']\n",
    "fires = fires[fires['ArchiveYear'] < 2019] # so 2018 fires match next years' data (2019)\n",
    "\n",
    "# Calculate acres burned per county per year and format\n",
    "acres_burned = fires.groupby([\"Counties\", \"ArchiveYear\"])[\"AcresBurned\"].sum().to_frame(name = 'AcresBurned')\n",
    "\n",
    "# Reset indexes so dataframe is singly indexed\n",
    "acres_burned = acres_burned.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate year-after employment statistics with yearly wildfire data\n",
    "\n",
    "Here, I associate employment statistics with wildfire data by creating a helper function to gather year-after-fire data and year/ year-after-fire difference data for each year and county combination (e.g., Yuba county, 2017) and attach these as a new column in the acres_burned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function to gather year-after-fire data and year/ year-after-fire differences.\n",
    "\n",
    "def yearAfterStats(df1, df2, colname):\n",
    "    \"\"\"Get year-after-fire data and calculate year/ year-after-fire differences from df2 for each year-county combo in df1 and attach as new column named 'colname' to df1.\"\"\"\n",
    "    \n",
    "    # Catch year after fire values in a list\n",
    "    yafLst = []\n",
    "    # Catch year-of/year-after fire difference\n",
    "    yafDiffLst = []\n",
    "    # Catch year-before/year-of fire difference\n",
    "    yofDiffLst = []\n",
    "\n",
    "    # Iterate over each row in df1\n",
    "    for index, row in df1.iterrows():\n",
    "        # Get the county\n",
    "        county = str(row[0])\n",
    "        \n",
    "        # Get the year before fire\n",
    "        ybf = str(row[1] - 1)\n",
    "        # Get the year of fire\n",
    "        yof = str(row[1])\n",
    "        # Get the year after fire\n",
    "        yaf = str(row[1] + 1)\n",
    "        \n",
    "        # Get labor stat from the year before fire/county combo from df2\n",
    "        ybfVal = df2.loc[ybf, county]\n",
    "        # Get labor stat from the year of fire/county combo from df2\n",
    "        yofVal = df2.loc[yof, county]\n",
    "        # Get labor stat from the year after fire/county combo from df2 \n",
    "        yafVal = df2.loc[yaf, county]\n",
    "        \n",
    "        # Calculate difference year-of and year-after values\n",
    "        yafDiff = yofVal - yafVal\n",
    "        # Calculate difference year-before and year-of values\n",
    "        yofDiff = ybfVal - yofVal\n",
    "\n",
    "        # Append year-after values to the appropriate list.\n",
    "        yafLst.append(yafVal)\n",
    "        # Append year-after values to the appropriate list.\n",
    "        yafDiffLst.append(yafDiff)\n",
    "        # Append year-after values to the appropriate list.\n",
    "        yofDiffLst.append(yofDiff)\n",
    "\n",
    "    # Create full column name\n",
    "    colname_yaf = colname + 'Yaf'\n",
    "    # Attach to dataframe\n",
    "    df1[colname_yaf] = yafLst\n",
    "\n",
    "    # Create full column name\n",
    "    colname_yafdiff = colname + 'ChangeYaf'\n",
    "    # Attach to dataframe\n",
    "    df1[colname_yafdiff] = yafDiffLst\n",
    "\n",
    "    # Create full column name\n",
    "    colname_yofdiff = colname + 'ChangeYof'\n",
    "    # Attach to dataframe\n",
    "    df1[colname_yofdiff] = yofDiffLst  \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nunemp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-f2c912ff9f74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0myearAfterStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macres_burned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlabor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nLabor'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0myearAfterStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macres_burned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nEmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0myearAfterStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macres_burned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnunemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nUnemp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0myearAfterStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macres_burned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rUnemp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0myearAfterStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macres_burned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nPop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nunemp' is not defined"
     ]
    }
   ],
   "source": [
    "yearAfterStats(acres_burned, nlabor, 'nLabor')\n",
    "yearAfterStats(acres_burned, nemp, 'nEmp')\n",
    "yearAfterStats(acres_burned, nunemp, 'nUnemp')\n",
    "yearAfterStats(acres_burned, runemp, 'rUnemp')\n",
    "yearAfterStats(acres_burned, population, 'nPop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acres_burned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality\n",
    "\n",
    "Many statistical methods (e.g., parametric statistical tests and many machine learning methods) assume variables are normally distributed; if this assumption is violated, these methods may produce inaccurate and misleading results. Non-normal data may be transformed or analyzed with non-parametric tests.\n",
    "\n",
    "To determine if the variables examined here follow a normal distribution, I begin with a visual examination of the data and follow by applying Shapiro-Wilkes tests of normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only continuous data\n",
    "burn_data = acres_burned.drop(['Counties', 'ArchiveYear'], axis=1)\n",
    "# Plot variables against each other\n",
    "sns.pairplot(burn_data) # Diagonal (top-left to bottom-right) are histograms of \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of the diagonal histograms (above) indicates none of the numeric data are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = []\n",
    "pval = []\n",
    "shapiro_W = []\n",
    "for name, values in burn_data.iteritems():\n",
    "    variable.append(name)\n",
    "    res = stats.shapiro(values)\n",
    "    shapiro_W.append(res[0])\n",
    "    pval.append(res[1])\n",
    "\n",
    "norm_res = {'variable': variable, 'p-value': pval, 'W-score': shapiro_W}\n",
    "shapiro_normality = pd.DataFrame(data = norm_res)\n",
    "shapiro_normality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, Shapiro-Wilkes tests for normality (above) indicate none of the data are normally distributed. Here, significant p-values for each variable reject the null hypotheses that the distributions are not statistically different from a normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a log transform to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_data1 = acres_burned[['AcresBurned', 'nlabor_yaf', 'nemp_yaf', 'runemp_yaf', 'nunemp_yaf', 'pop_yf', 'pop_yaf', 'deltapop_yaf']]\n",
    "\n",
    "for name, values in burn_data.iteritems():\n",
    "    namea = name + '_log'\n",
    "    vals = []\n",
    "    for i in values:\n",
    "        if i > 0:\n",
    "            vals.append(math.log(i))\n",
    "        else:\n",
    "            vals.append(np.NaN)\n",
    "    burn_data1[namea] = vals\n",
    "    \n",
    "burn_data = burn_data1[['AcresBurned', 'nlabor_yaf', 'nemp_yaf', 'runemp_yaf', 'nunemp_yaf', 'pop_yf', 'pop_yaf', 'deltapop_yaf']]\n",
    "    \n",
    "burn_data_log = burn_data1[['AcresBurned_log', 'nlabor_yaf_log', 'nemp_yaf_log', 'runemp_yaf_log', 'nunemp_yaf_log', 'pop_yf_log', 'pop_yaf_log', 'deltapop_yaf_log']]\n",
    "#burn_data_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapiro-Wilkes test for normality of log transformed data are normally distributed- except for runemp_yaf_log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = []\n",
    "pval = []\n",
    "shapiro_W = []\n",
    "for name, values in burn_data_log.iteritems():\n",
    "    variable.append(name)\n",
    "    vals = values[np.logical_not(np.isnan(values))]    \n",
    "    res = stats.shapiro(vals)\n",
    "    shapiro_W.append(res[0])\n",
    "    pval.append(res[1])\n",
    "\n",
    "norm_res = {'variable': variable, 'p-value': pval, 'W-score': shapiro_W}\n",
    "shapiro_normality_log = pd.DataFrame(data = norm_res)\n",
    "shapiro_normality_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(burn_data_log, kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(acres_burned['AcresBurned'], acres_burned['nlabor_yaf'], label='Civilian Labor Force (n)')\n",
    "plt.scatter(acres_burned['AcresBurned'], acres_burned['nemp_yaf'], label='Employed (n)')\n",
    "plt.scatter(acres_burned['AcresBurned'], acres_burned['nunemp_yaf'], label='Unemployed (n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(acres_burned['AcresBurned'], acres_burned['pop_yaf'], label='Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(acres_burned['AcresBurned'], acres_burned['runemp_yaf'], label='Unemployment Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(acres_burned['AcresBurned'], acres_burned['deltapop_yaf'], label='Change in Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
